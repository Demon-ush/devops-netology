# Домашнее задание к занятию "6.5. Elasticsearch"


## Pадача 1
В этом задании вы потренируетесь в:
- установке elasticsearch
- первоначальном конфигурировании elastcisearch
- запуске elasticsearch в docker
Используя докер образ centos:7 как базовый и документацию по установке и запуску Elastcisearch:
- составьте Dockerfile-манифест для elasticsearch
- соберите docker-образ и сделайте push в ваш docker.io репозиторий
- запустите контейнер из получившегося образа и выполните запрос пути / c хост-машины
Требования к elasticsearch.yml:
- данные path должны сохраняться в /var/lib
- имя ноды должно быть netology_test
В ответе приведите:
- текст Dockerfile манифеста
- ссылку на образ в репозитории dockerhub
- ответ elasticsearch на запрос пути / в json виде
Подсказки:
- возможно понадобится установка пакета perl-Digest-SHA для корректной работы пакета shasum
- при сетевых проблемах внимательно изучить кластерные и сетевые настройки в elasticsearch.yml
- при некоторых проблемах поможет docker директива ulimit
- elasticsearch в логах обычно описывает проблему и пути ее решения
Далее будет работа с данным экземпляром elasticsearch.


### Ответ:
```
С учётом того, что в настоящий момент скачивание Elastic-а с официального сайта, установка из пакетов
или получение docher-образа сопровождается ошибкой «403 Forbiden» (т.е., невозможно), то ответ
по большей части теоретический.
Вариант с созданием образа из рабочей ВМ с установленным elastic-ом не сработал – вылезают ошибки
(установка оказалась битая), а все попытки исправления приводят к обращениям к оф.сайту и неизменным
отлупом…
Образ, собранный из ВМ выложен… но он неудачен, так как практически нерабочий...
Собирался 8 elastic на 8 centos (что было)...

По правилам и по документации:
Dockerfile:
------------------------------------------------------------------
#6.5. Elasticsearch
FROM centos:8
LABEL Homework 6.5 Elasticsearch

ENV PATH=/usr/lib:/usr/lib/jvm/jre-11/bin:$PATH
ENV JAVA_HOME=/elasticsearch-8.2.0/jdk/
ENV ES_HOME=/elasticsearch-8.2.0

RUN groupadd elasticsearch
RUN useradd -g elasticsearch elasticsearch

RUN mkdir /opt/elastic-data
RUN mkdir /opt/elastic-data/data
RUN mkdir /opt/elastic-data/logs
RUN mkdir /opt/elastic-data/snapshots
RUN chown –R elasticsearch: /opt/elastic-data

RUN yum install perl-Digest-SHA -y
RUN yum install wget -y
RUN yum install mc

RUN wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.0-linux-x86_64.tar.gz \
RUN wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.0-linux-x86_64.tar.gz.sha512
RUN shasum -a 512 -c elasticsearch-8.2.0-linux-x86_64.tar.gz.sha512

RUN cd /opt
RUN tar -xzf elasticsearch-8.2.0-linux-x86_64.tar.gz
RUN chown –R elasticsearch: /opt/elasticsearch-8.2.0

ADD elasticsearch.yml /elasticsearch-8.2.0/config/

USER elasticsearch
CMD ["/usr/sbin/init"]
CMD ["/opt/elasticsearch-8.2.0/bin/elasticsearch"]
------------------------------------------------------------------

docker commit -m "elastic 8.2 on centos 8" -a bem 6edf6617c4d5 my_elastic

docker images
REPOSITORY                   TAG       IMAGE ID       CREATED        SIZE
my_elastic                   latest    2d4354f92940   2 days ago     1.35GB
------------------------------------------------------------------

docker login
docker push my_elastic

Файл конфигурации elasticsearch.yml

# ======================== Elasticsearch Configuration =========================
#
# NOTE: Elasticsearch comes with reasonable defaults for most settings.
#       Before you set out to tweak and tune the configuration, make sure you
#       understand what are you trying to accomplish and the consequences.
#
# The primary way of configuring a node is via this file. This template lists
# the most important settings you may want to configure for a production cluster.
#
# Please consult the documentation for further information on configuration options:
# https://www.elastic.co/guide/en/elasticsearch/reference/index.html
#
# ---------------------------------- Cluster -----------------------------------
#
# Use a descriptive name for your cluster:
#
cluster.name: netology_test
discovery.type: single-node
#
# ------------------------------------ Node ------------------------------------
#
# Use a descriptive name for the node:
#
#node.name: node-1
#
# Add custom attributes to the node:
#
#node.attr.rack: r1
#
# ----------------------------------- Paths ------------------------------------
#
# Path to directory where to store the data (separate multiple locations by comma):
#
path.data: /opt/elastic-data/data
#
# Path to log files:
#
path.logs: /opt/elastic-data/logs
#
#Settings REPOSITORY PATH
#
path.repo: /opt/elastic-data/snapshots
#
# ----------------------------------- Memory -----------------------------------
#
# Lock the memory on startup:
#
#bootstrap.memory_lock: true
#
# Make sure that the heap size is set to about half the memory available
# on the system and that the owner of the process is allowed to use this
# limit.
#
# Elasticsearch performs poorly when the system is swapping the memory.
#
# ---------------------------------- Network -----------------------------------
#
# Set the bind address to a specific IP (IPv4 or IPv6):
#
network.host: localhost
#
# Set a custom port for HTTP:
#
#http.port: 9200
#
# For more information, consult the network module documentation.
#
# --------------------------------- Discovery ----------------------------------
#
# Pass an initial list of hosts to perform discovery when this node is started:
# The default list of hosts is ["127.0.0.1", "[::1]"]
#
discovery.seed_hosts: ["127.0.0.1", "[::1]"]
#
# Bootstrap the cluster using an initial set of master-eligible nodes:
#
#cluster.initial_master_nodes: ["node-1", "node-2"]
#
# For more information, consult the discovery and cluster formation module documentation.
#
# ---------------------------------- Gateway -----------------------------------
#
# Block initial recovery after a full cluster restart until N nodes are started:
#
#gateway.recover_after_nodes: 3
#
# For more information, consult the gateway module documentation.
#
# ---------------------------------- Various -----------------------------------
#
# Require explicit names when deleting indices:
#
#action.destructive_requires_name: true


Ответ GET / должнобыт что-то вроде
{
  "name" : "688a5504634С учётом того, что в настоящий момент скачивание Elastic-а с официального сайта, установка из пакетов или получение docher-образа сопровождается ошибкой «403 Forbiden» (т.е., невозможно), то ответ по большей части теоретический.
Вариант с созданием образа из рабочей ВМ с установленным elastic-ом не работал – вылезают ошибки, при попытке исправить которые идёт обращение к оф.сайту и неизменным отлупом…
Образ, собранный из боевой ВМ выложен…

По правилам и по документации:
Dockerfile:
------------------------------------------------------------------
#6.5. Elasticsearch
FROM centos:8
LABEL Homework 6.5 Elasticsearch

ENV PATH=/usr/lib:/usr/lib/jvm/jre-11/bin:$PATH
ENV JAVA_HOME=/elasticsearch-8.2.0/jdk/
ENV ES_HOME=/elasticsearch-8.2.0

RUN groupadd elasticsearch
RUN useradd -g elasticsearch elasticsearch

RUN mkdir /opt/elastic-data
RUN mkdir /opt/elastic-data/data
RUN mkdir /opt/elastic-data/logs
RUN mkdir /opt/elastic-data/snapshots
RUN chown –R elasticsearch: /opt/elastic-data

RUN yum install perl-Digest-SHA -y
RUN yum install wget -y
RUN yum install mc

RUN wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.0-linux-x86_64.tar.gz \
RUN wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.0-linux-x86_64.tar.gz.sha512
RUN shasum -a 512 -c elasticsearch-8.2.0-linux-x86_64.tar.gz.sha512

RUN cd /opt
RUN tar -xzf elasticsearch-8.2.0-linux-x86_64.tar.gz
RUN chown –R elasticsearch: /opt/elasticsearch-8.2.0

ADD elasticsearch.yml /elasticsearch-8.2.0/config/

USER elasticsearch
CMD ["/usr/sbin/init"]
CMD ["/elasticsearch-8.2.0/bin/elasticsearch"]
------------------------------------------------------------------

docker commit -m "elastic 8.2 on centos 8" -a bem 6edf6617c4d5 my_elastic

docker images
REPOSITORY                   TAG       IMAGE ID       CREATED        SIZE
my_elastic                   latest    2d4354f92940   2 days ago     1.35GB
------------------------------------------------------------------

docker login
docker push my_elastic

Файл конфигурации elasticsearch.yml

# ======================== Elasticsearch Configuration =========================
#
# NOTE: Elasticsearch comes with reasonable defaults for most settings.
#       Before you set out to tweak and tune the configuration, make sure you
#       understand what are you trying to accomplish and the consequences.
#
# The primary way of configuring a node is via this file. This template lists
# the most important settings you may want to configure for a production cluster.
#
# Please consult the documentation for further information on configuration options:
# https://www.elastic.co/guide/en/elasticsearch/reference/index.html
#
# ---------------------------------- Cluster -----------------------------------
#
# Use a descriptive name for your cluster:
#
cluster.name: netology_test
discovery.type: single-node
#
# ------------------------------------ Node ------------------------------------
#
# Use a descriptive name for the node:
#
#node.name: node-1
#
# Add custom attributes to the node:
#
#node.attr.rack: r1
#
# ----------------------------------- Paths ------------------------------------
#
# Path to directory where to store the data (separate multiple locations by comma):
#
path.data: /opt/elastic-data/data
#
# Path to log files:
#
path.logs: /opt/elastic-data/logs
#
#Settings REPOSITORY PATH
#
path.repo: /opt/elastic-data/snapshots
#
# ----------------------------------- Memory -----------------------------------
#
# Lock the memory on startup:
#
#bootstrap.memory_lock: true
#
# Make sure that the heap size is set to about half the memory available
# on the system and that the owner of the process is allowed to use this
# limit.
#
# Elasticsearch performs poorly when the system is swapping the memory.
#
# ---------------------------------- Network -----------------------------------
#
# Set the bind address to a specific IP (IPv4 or IPv6):
#
network.host: localhost
#
# Set a custom port for HTTP:
#
#http.port: 9200
#
# For more information, consult the network module documentation.
#
# --------------------------------- Discovery ----------------------------------
#
# Pass an initial list of hosts to perform discovery when this node is started:
# The default list of hosts is ["127.0.0.1", "[::1]"]
#
discovery.seed_hosts: ["127.0.0.1", "[::1]"]
#
# Bootstrap the cluster using an initial set of master-eligible nodes:
#
#cluster.initial_master_nodes: ["node-1", "node-2"]
#
# For more information, consult the discovery and cluster formation module documentation.
#
# ---------------------------------- Gateway -----------------------------------
#
# Block initial recovery after a full cluster restart until N nodes are started:
#
#gateway.recover_after_nodes: 3
#
# For more information, consult the gateway module documentation.
#
# ---------------------------------- Various -----------------------------------
#
# Require explicit names when deleting indices:
#
#action.destructive_requires_name: true

```

## Задача 2
В этом задании вы научитесь:
- создавать и удалять индексы
- изучать состояние кластера
- обосновывать причину деградации доступности данных
Ознакомтесь с документацией и добавьте в elasticsearch 3 индекса, в соответствии со таблицей:
Имя     Количество реплик       Количество шард
ind-1   0                       1
ind-2   1                       2
ind-3   2                       4
Получите список индексов и их статусов, используя API и приведите в ответе на задание.
Получите состояние кластера elasticsearch, используя API.
Как вы думаете, почему часть индексов и кластер находится в состоянии yellow?
Удалите все индексы.
    Важно
    При проектировании кластера elasticsearch нужно корректно рассчитывать количество реплик и шард,
    иначе возможна потеря данных индексов, вплоть до полной, при деградации системы.


### Ответ:
```
Создание индексов:
curl -X PUT localhost:9200/index-1 -H 'Content-Type: application/json' -d'{ "settings": { "number_of_shards": 1,  "number_of_replicas": 0 }}'
curl -X PUT localhost:9200/index-2 -H 'Content-Type: application/json' -d'{ "settings": { "number_of_shards": 2,  "number_of_replicas": 1 }}'
curl -X PUT localhost:9200/index-3 -H 'Content-Type: application/json' -d'{ "settings": { "number_of_shards": 4,  "number_of_replicas": 2 }}'

Список индексов:
curl -X GET 'http://localhost:9200/_cat/indices?v&pretty'

Статус индексов:
curl -X GET 'http://localhost:9200/_index/health/index-1?pretty'
curl -X GET 'http://localhost:9200/_index/health/index-2?pretty'
curl -X GET 'http://localhost:9200/_index/health/index-3?pretty'

    Первый индекс будет зелёный, 2 и 3-ий - жёлтые, т.к. задано число реплик, а инстанс один,
    т.е., реплицироваться некуда...

    Примечание: Чтобы посмотреть все индексы и их поля, можно применить команду глобально
                curl 'localhost:9200/_mapping?pretty'

Статус кластера:
curl -XGET localhost:9200/_cluster/health/?pretty=true

Удаление индексов:
curl -X DELETE 'http://localhost:9200/index-1?pretty'
curl -X DELETE 'http://localhost:9200/index-2?pretty'
curl -X DELETE 'http://localhost:9200/index-3?pretty'

$ curl -X GET 'http://localhost:9200/_cat/indices?v'

```

## Задача 3
В данном задании вы научитесь:
- создавать бэкапы данных
- восстанавливать индексы из бэкапов
Создайте директорию {путь до корневой директории с elasticsearch в образе}/snapshots.
Используя API зарегистрируйте данную директорию как snapshot repository c именем netology_backup.
Приведите в ответе запрос API и результат вызова API для создания репозитория.
Создайте индекс test с 0 реплик и 1 шардом и приведите в ответе список индексов.
Создайте snapshot состояния кластера elasticsearch.
Приведите в ответе список файлов в директории со snapshotами.
Удалите индекс test и создайте индекс test-2. Приведите в ответе список индексов.
Восстановите состояние кластера elasticsearch из snapshot, созданного ранее.
Приведите в ответе запрос к API восстановления и итоговый список индексов.
    Подсказки:
    - возможно вам понадобится доработать elasticsearch.yml в части директивы path.repo и
    перезапустить elasticsearch


### Ответ:
```
Создать директорию для snapshot-ов:
curl -XPOST localhost:9200/_snapshot/netology_backup?pretty -H 'Content-Type: application/json' -d'{"type": "fs", "settings": { "location":"/opt/elastic-data/snapshots" }}'

curl -X PUT localhost:9200/test -H 'Content-Type: application/json' -d'{ "settings": { "number_of_shards": 1,  "number_of_replicas": 0 }}'
{"acknowledged":true,"shards_acknowledged":true,"index":"test"}1

$ curl -X PUT localhost:9200/_snapshot/netology_backup/elasticsearch?wait_for_completion=true
{"snapshot":{"snapshot":"elasticsearch","uuid":"wixOT9zMS_WYXlGfNw7nsQ","version_id":7110199,"version":"7.11.1","indices":["test"],"data_streams":[],"include_global_state":true,"state":"SUCCESS","start_time":"2021-03-06T12:23:31.388Z","start_time_in_millis":1615033411388,"end_time":"2021-03-06T12:23:31.988Z","end_time_in_millis":1615033411988,"duration_in_millis":600,"failures":[],"shards":{"total":1,"failed":0,"successful":1}}}

Удаление и создание нового индекса:

curl -X DELETE 'http://localhost:9200/test?pretty'

curl -X PUT localhost:9200/test-2?pretty -H 'Content-Type: application/json' -d'{ "settings": { "number_of_shards": 1,  "number_of_replicas": 0 }}'

curl -X POST localhost:9200/_snapshot/netology_backup/elasticsearch/_restore?pretty -H 'Content-Type: application/json' -d'{"include_global_state":true}'

curl -X GET http://localhost:9200/_cat/indices?v

```

